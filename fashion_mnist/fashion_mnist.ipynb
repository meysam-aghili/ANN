{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "img = Image.fromarray(x_train[1], 'RGB')\n",
    "img.show()\n",
    "\n",
    "plt.imshow(np.dot(x_train[1], [0.2989, 0.5870, 0.1140]), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = np.dot(x_train[...,:3], [0.2989, 0.5870, 0.1140]), np.dot(x_test[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "x_train, x_test = x_train/255 , x_test/255\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.15, shuffle=True)\n",
    "#y_train = tf.one_hot(y_train.astype(np.int32), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(32,32)),\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\", name=\"layer1\"),\n",
    "        tf.keras.layers.Dense(60, activation=\"relu\", name=\"layer2\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 2.1422 - accuracy: 0.1999 - val_loss: 2.0985 - val_accuracy: 0.2424\n",
      "Epoch 2/50\n",
      "1329/1329 [==============================] - 6s 5ms/step - loss: 1.9536 - accuracy: 0.2944 - val_loss: 1.9706 - val_accuracy: 0.2829\n",
      "Epoch 3/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.8762 - accuracy: 0.3262 - val_loss: 1.9358 - val_accuracy: 0.3119\n",
      "Epoch 4/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.8276 - accuracy: 0.3472 - val_loss: 1.8991 - val_accuracy: 0.3188\n",
      "Epoch 5/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.7900 - accuracy: 0.3615 - val_loss: 1.8658 - val_accuracy: 0.3376\n",
      "Epoch 6/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.7601 - accuracy: 0.3742 - val_loss: 1.8026 - val_accuracy: 0.3524\n",
      "Epoch 7/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.7301 - accuracy: 0.3857 - val_loss: 1.8279 - val_accuracy: 0.3544\n",
      "Epoch 8/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.7064 - accuracy: 0.3922 - val_loss: 1.8262 - val_accuracy: 0.3595\n",
      "Epoch 9/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6864 - accuracy: 0.4018 - val_loss: 1.7826 - val_accuracy: 0.3645\n",
      "Epoch 10/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6723 - accuracy: 0.4074 - val_loss: 1.8811 - val_accuracy: 0.3300\n",
      "Epoch 11/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6590 - accuracy: 0.4134 - val_loss: 1.7534 - val_accuracy: 0.3832\n",
      "Epoch 12/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6472 - accuracy: 0.4178 - val_loss: 1.7922 - val_accuracy: 0.3699\n",
      "Epoch 13/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6372 - accuracy: 0.4214 - val_loss: 1.8857 - val_accuracy: 0.3460\n",
      "Epoch 14/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.6206 - accuracy: 0.4251 - val_loss: 1.8800 - val_accuracy: 0.3479\n",
      "Epoch 15/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.6154 - accuracy: 0.4261 - val_loss: 1.9421 - val_accuracy: 0.3651\n",
      "Epoch 16/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.6052 - accuracy: 0.4309 - val_loss: 1.9262 - val_accuracy: 0.3643\n",
      "Epoch 17/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.5902 - accuracy: 0.4365 - val_loss: 1.7929 - val_accuracy: 0.3844\n",
      "Epoch 18/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.5849 - accuracy: 0.4379 - val_loss: 1.9727 - val_accuracy: 0.3572\n",
      "Epoch 19/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5802 - accuracy: 0.4424 - val_loss: 1.8297 - val_accuracy: 0.3891\n",
      "Epoch 20/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5705 - accuracy: 0.4440 - val_loss: 2.1195 - val_accuracy: 0.3447\n",
      "Epoch 21/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5686 - accuracy: 0.4440 - val_loss: 1.8250 - val_accuracy: 0.3861\n",
      "Epoch 22/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5627 - accuracy: 0.4481 - val_loss: 1.8139 - val_accuracy: 0.3988\n",
      "Epoch 23/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5557 - accuracy: 0.4503 - val_loss: 1.8621 - val_accuracy: 0.3788\n",
      "Epoch 24/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5549 - accuracy: 0.4519 - val_loss: 1.8138 - val_accuracy: 0.3947\n",
      "Epoch 25/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5426 - accuracy: 0.4547 - val_loss: 1.8413 - val_accuracy: 0.3968\n",
      "Epoch 26/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5420 - accuracy: 0.4594 - val_loss: 1.8857 - val_accuracy: 0.3895\n",
      "Epoch 27/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5337 - accuracy: 0.4585 - val_loss: 2.0770 - val_accuracy: 0.3463\n",
      "Epoch 28/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5380 - accuracy: 0.4578 - val_loss: 2.0030 - val_accuracy: 0.3688\n",
      "Epoch 29/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.5306 - accuracy: 0.4610 - val_loss: 1.9411 - val_accuracy: 0.3785\n",
      "Epoch 30/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.5246 - accuracy: 0.4646 - val_loss: 1.9426 - val_accuracy: 0.3712\n",
      "Epoch 31/50\n",
      "1329/1329 [==============================] - 5s 4ms/step - loss: 1.5247 - accuracy: 0.4631 - val_loss: 2.0904 - val_accuracy: 0.3689\n",
      "Epoch 32/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5263 - accuracy: 0.4647 - val_loss: 1.9137 - val_accuracy: 0.3945\n",
      "Epoch 33/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5191 - accuracy: 0.4655 - val_loss: 2.0576 - val_accuracy: 0.3679\n",
      "Epoch 34/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5187 - accuracy: 0.4662 - val_loss: 1.9864 - val_accuracy: 0.3927\n",
      "Epoch 35/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5082 - accuracy: 0.4695 - val_loss: 2.0825 - val_accuracy: 0.3617\n",
      "Epoch 36/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5020 - accuracy: 0.4694 - val_loss: 2.5524 - val_accuracy: 0.3203\n",
      "Epoch 37/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5024 - accuracy: 0.4688 - val_loss: 2.4385 - val_accuracy: 0.3143\n",
      "Epoch 38/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.5021 - accuracy: 0.4721 - val_loss: 2.1834 - val_accuracy: 0.3412\n",
      "Epoch 39/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4944 - accuracy: 0.4761 - val_loss: 1.9587 - val_accuracy: 0.3947\n",
      "Epoch 40/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4855 - accuracy: 0.4764 - val_loss: 1.9963 - val_accuracy: 0.3989\n",
      "Epoch 41/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4875 - accuracy: 0.4823 - val_loss: 2.1303 - val_accuracy: 0.3633\n",
      "Epoch 42/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4896 - accuracy: 0.4801 - val_loss: 2.0768 - val_accuracy: 0.3635\n",
      "Epoch 43/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4815 - accuracy: 0.4806 - val_loss: 2.2170 - val_accuracy: 0.3528\n",
      "Epoch 44/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4727 - accuracy: 0.4836 - val_loss: 2.2077 - val_accuracy: 0.3413\n",
      "Epoch 45/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4764 - accuracy: 0.4829 - val_loss: 2.1491 - val_accuracy: 0.3493\n",
      "Epoch 46/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4681 - accuracy: 0.4886 - val_loss: 2.2322 - val_accuracy: 0.3699\n",
      "Epoch 47/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4580 - accuracy: 0.4904 - val_loss: 2.1110 - val_accuracy: 0.3967\n",
      "Epoch 48/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4618 - accuracy: 0.4857 - val_loss: 2.2439 - val_accuracy: 0.3481\n",
      "Epoch 49/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4534 - accuracy: 0.4907 - val_loss: 2.2880 - val_accuracy: 0.3869\n",
      "Epoch 50/50\n",
      "1329/1329 [==============================] - 6s 4ms/step - loss: 1.4502 - accuracy: 0.4921 - val_loss: 2.0995 - val_accuracy: 0.3792\n"
     ]
    }
   ],
   "source": [
    "EarlyStopping_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "ModelCheckpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoint\", save_best_only=True)\n",
    "TensorBoard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "model_history = model.fit(x=x_train, y=y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val), callbacks=[EarlyStopping_callback, ModelCheckpoint_callback, TensorBoard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a56f890a61c577e7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a56f890a61c577e7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8877;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs --port=8877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plotmodelhistory(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "    \"\"\"\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label') \n",
    "    ax.set_ylabel('True Label')\n",
    "    \n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "    \"\"\"\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
    "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(pred, axis=1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_test_errors = x_test[errors]\n",
    "\n",
    "cm = confusion_matrix(Y_true, Y_pred_classes) \n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "im, cbar = heatmap(cm, labels, labels, ax=ax,\n",
    "                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\n",
    "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 3\n",
    "C = 5\n",
    "fig, axes = plt.subplots(R, C, figsize=(12,8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "misclassified_idx = np.where(Y_pred_classes != Y_true)[0]\n",
    "for i in np.arange(0, R*C):\n",
    "    axes[i].imshow(x_test[misclassified_idx[i]])\n",
    "    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]], \n",
    "                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cifar10_.h5\")\n",
    "tf.keras.models.load_model(\"cifar10_.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "121224a4c1993777890f5a950b35779c5da0f359f16b8ef38518e852de891dec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
